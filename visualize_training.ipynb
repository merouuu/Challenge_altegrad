{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualisation des Courbes d'Entra√Ænement\n",
        "\n",
        "Ce notebook permet de visualiser les m√©triques d'entra√Ænement des mod√®les Graph Transformer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "BASE_PATH = \"data\"  # Changez en \"/content/drive/MyDrive/data\" pour Colab\n",
        "MODELS = {\n",
        "    \"GT (MSE)\": f\"{BASE_PATH}/GT/training_logs.json\",\n",
        "    \"GT Contrast (Improved)\": f\"{BASE_PATH}/GT_Contrast/training_logs.json\"\n",
        "}\n",
        "\n",
        "# Couleurs pour les graphiques\n",
        "COLORS = {\n",
        "    \"GT (MSE)\": \"#1f77b4\",\n",
        "    \"GT Contrast (Improved)\": \"#ff7f0e\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_logs(log_path):\n",
        "    \"\"\"Charge les logs d'entra√Ænement depuis un fichier JSON\"\"\"\n",
        "    if not os.path.exists(log_path):\n",
        "        print(f\"‚ö†Ô∏è  Fichier non trouv√©: {log_path}\")\n",
        "        return None\n",
        "    \n",
        "    with open(log_path, 'r') as f:\n",
        "        logs = json.load(f)\n",
        "    return logs\n",
        "\n",
        "# Charger tous les logs disponibles\n",
        "all_logs = {}\n",
        "for model_name, log_path in MODELS.items():\n",
        "    logs = load_logs(log_path)\n",
        "    if logs is not None:\n",
        "        all_logs[model_name] = logs\n",
        "        print(f\"‚úÖ {model_name}: {len(logs['epochs'])} epochs charg√©s\")\n",
        "    else:\n",
        "        print(f\"‚ùå {model_name}: logs non disponibles\")\n",
        "\n",
        "if len(all_logs) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  Aucun log trouv√©. Assurez-vous d'avoir entra√Æn√© au moins un mod√®le.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Courbes de Loss (Train vs Validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Training Loss\n",
        "for model_name, logs in all_logs.items():\n",
        "    epochs = [e[\"epoch\"] for e in logs[\"epochs\"]]\n",
        "    train_losses = [e[\"train_loss\"] for e in logs[\"epochs\"]]\n",
        "    \n",
        "    ax1.plot(epochs, train_losses, \n",
        "             label=model_name, \n",
        "             color=COLORS.get(model_name, \"gray\"),\n",
        "             linewidth=2,\n",
        "             marker='o',\n",
        "             markersize=4)\n",
        "\n",
        "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax1.set_ylabel(\"Training Loss\", fontsize=12)\n",
        "ax1.set_title(\"Training Loss\", fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Loss\n",
        "for model_name, logs in all_logs.items():\n",
        "    epochs = [e[\"epoch\"] for e in logs[\"epochs\"] if e.get(\"val_loss\", 0) > 0]\n",
        "    val_losses = [e[\"val_loss\"] for e in logs[\"epochs\"] if e.get(\"val_loss\", 0) > 0]\n",
        "    \n",
        "    if len(epochs) > 0:\n",
        "        ax2.plot(epochs, val_losses, \n",
        "                 label=model_name, \n",
        "                 color=COLORS.get(model_name, \"gray\"),\n",
        "                 linewidth=2,\n",
        "                 marker='s',\n",
        "                 markersize=4,\n",
        "                 linestyle='--')\n",
        "\n",
        "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax2.set_ylabel(\"Validation Loss\", fontsize=12)\n",
        "ax2.set_title(\"Validation Loss\", fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Graphique combin√© Train vs Val pour d√©tecter l'overfitting\n",
        "plt.figure(figsize=(12, 6))\n",
        "for model_name, logs in all_logs.items():\n",
        "    epochs = [e[\"epoch\"] for e in logs[\"epochs\"]]\n",
        "    train_losses = [e[\"train_loss\"] for e in logs[\"epochs\"]]\n",
        "    val_losses = [e.get(\"val_loss\", None) for e in logs[\"epochs\"]]\n",
        "    \n",
        "    # Filtrer les epochs o√π val_loss existe\n",
        "    valid_epochs = [ep for ep, vl in zip(epochs, val_losses) if vl is not None and vl > 0]\n",
        "    valid_val_losses = [vl for vl in val_losses if vl is not None and vl > 0]\n",
        "    \n",
        "    plt.plot(epochs, train_losses, \n",
        "             label=f\"{model_name} (Train)\", \n",
        "             color=COLORS.get(model_name, \"gray\"),\n",
        "             linewidth=2,\n",
        "             marker='o',\n",
        "             markersize=4)\n",
        "    \n",
        "    if len(valid_epochs) > 0:\n",
        "        plt.plot(valid_epochs, valid_val_losses, \n",
        "                 label=f\"{model_name} (Val)\", \n",
        "                 color=COLORS.get(model_name, \"gray\"),\n",
        "                 linewidth=2,\n",
        "                 marker='s',\n",
        "                 markersize=4,\n",
        "                 linestyle='--',\n",
        "                 alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Loss\", fontsize=12)\n",
        "plt.title(\"Train vs Validation Loss (D√©tection d'Overfitting)\", fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. M√©triques de Validation (MRR, R@1, R@5, R@10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "metrics = [\"val_mrr\", \"val_r1\", \"val_r5\", \"val_r10\"]\n",
        "metric_names = [\"MRR (Mean Reciprocal Rank)\", \"R@1 (Recall@1)\", \"R@5 (Recall@5)\", \"R@10 (Recall@10)\"]\n",
        "\n",
        "for idx, (metric, metric_name) in enumerate(zip(metrics, metric_names)):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    for model_name, logs in all_logs.items():\n",
        "        epochs = [e[\"epoch\"] for e in logs[\"epochs\"] if e.get(metric, 0) > 0]\n",
        "        values = [e[metric] for e in logs[\"epochs\"] if e.get(metric, 0) > 0]\n",
        "        \n",
        "        if len(epochs) > 0:\n",
        "            ax.plot(epochs, values, \n",
        "                   label=model_name, \n",
        "                   color=COLORS.get(model_name, \"gray\"),\n",
        "                   linewidth=2,\n",
        "                   marker='o',\n",
        "                   markersize=4)\n",
        "    \n",
        "    ax.set_xlabel(\"Epoch\", fontsize=10)\n",
        "    ax.set_ylabel(metric_name, fontsize=10)\n",
        "    ax.set_title(metric_name, fontsize=11, fontweight='bold')\n",
        "    ax.legend(fontsize=9)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. √âvolution du Learning Rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for model_name, logs in all_logs.items():\n",
        "    epochs = [e[\"epoch\"] for e in logs[\"epochs\"]]\n",
        "    learning_rates = [e[\"learning_rate\"] for e in logs[\"epochs\"]]\n",
        "    \n",
        "    plt.plot(epochs, learning_rates, \n",
        "             label=model_name, \n",
        "             color=COLORS.get(model_name, \"gray\"),\n",
        "             linewidth=2,\n",
        "             marker='s',\n",
        "             markersize=4)\n",
        "\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Learning Rate\", fontsize=12)\n",
        "plt.title(\"√âvolution du Learning Rate\", fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.yscale('log')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Tableau R√©capitulatif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cr√©er un tableau r√©capitulatif\n",
        "summary_data = []\n",
        "\n",
        "for model_name, logs in all_logs.items():\n",
        "    config = logs.get(\"config\", {})\n",
        "    best_mrr = logs.get(\"best_mrr\", 0.0)\n",
        "    \n",
        "    # Derni√®res m√©triques\n",
        "    if len(logs[\"epochs\"]) > 0:\n",
        "        last_epoch = logs[\"epochs\"][-1]\n",
        "        summary_data.append({\n",
        "            \"Mod√®le\": model_name,\n",
        "            \"Epochs\": config.get(\"epochs\", \"N/A\"),\n",
        "            \"LR\": config.get(\"lr\", \"N/A\"),\n",
        "            \"Batch Size\": config.get(\"batch_size\", \"N/A\"),\n",
        "            \"Best MRR\": f\"{best_mrr:.4f}\",\n",
        "            \"Last MRR\": f\"{last_epoch.get('val_mrr', 0.0):.4f}\",\n",
        "            \"Last R@1\": f\"{last_epoch.get('val_r1', 0.0):.4f}\",\n",
        "            \"Last R@5\": f\"{last_epoch.get('val_r5', 0.0):.4f}\",\n",
        "            \"Last R@10\": f\"{last_epoch.get('val_r10', 0.0):.4f}\",\n",
        "            \"Train Loss\": f\"{last_epoch.get('train_loss', 0.0):.4f}\",\n",
        "            \"Val Loss\": f\"{last_epoch.get('val_loss', 0.0):.4f}\"\n",
        "        })\n",
        "\n",
        "if summary_data:\n",
        "    df = pd.DataFrame(summary_data)\n",
        "    print(\"\\nüìä R√©capitulatif des Mod√®les:\\n\")\n",
        "    print(df.to_string(index=False))\n",
        "else:\n",
        "    print(\"Aucune donn√©e disponible.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comparaison C√¥te √† C√¥te (Loss vs MRR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Loss\n",
        "for model_name, logs in all_logs.items():\n",
        "    epochs = [e[\"epoch\"] for e in logs[\"epochs\"]]\n",
        "    train_losses = [e[\"train_loss\"] for e in logs[\"epochs\"]]\n",
        "    \n",
        "    ax1.plot(epochs, train_losses, \n",
        "            label=model_name, \n",
        "            color=COLORS.get(model_name, \"gray\"),\n",
        "            linewidth=2,\n",
        "            marker='o',\n",
        "            markersize=4)\n",
        "\n",
        "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax1.set_ylabel(\"Training Loss\", fontsize=12)\n",
        "ax1.set_title(\"Training Loss\", fontsize=13, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# MRR\n",
        "for model_name, logs in all_logs.items():\n",
        "    epochs = [e[\"epoch\"] for e in logs[\"epochs\"] if e.get(\"val_mrr\", 0) > 0]\n",
        "    mrr_values = [e[\"val_mrr\"] for e in logs[\"epochs\"] if e.get(\"val_mrr\", 0) > 0]\n",
        "    \n",
        "    if len(epochs) > 0:\n",
        "        ax2.plot(epochs, mrr_values, \n",
        "                label=model_name, \n",
        "                color=COLORS.get(model_name, \"gray\"),\n",
        "                linewidth=2,\n",
        "                marker='o',\n",
        "                markersize=4)\n",
        "\n",
        "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
        "ax2.set_ylabel(\"MRR\", fontsize=12)\n",
        "ax2.set_title(\"Validation MRR\", fontsize=13, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyse D√©taill√©e d'un Mod√®le\n",
        "\n",
        "S√©lectionnez un mod√®le pour voir ses d√©tails complets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S√©lectionner un mod√®le (changez le nom si n√©cessaire)\n",
        "selected_model = list(all_logs.keys())[0] if all_logs else None\n",
        "\n",
        "if selected_model:\n",
        "    logs = all_logs[selected_model]\n",
        "    \n",
        "    print(f\"\\nüìà Analyse d√©taill√©e: {selected_model}\\n\")\n",
        "    print(f\"Configuration:\")\n",
        "    for key, value in logs.get(\"config\", {}).items():\n",
        "        print(f\"  - {key}: {value}\")\n",
        "    \n",
        "    print(f\"\\nMeilleur MRR: {logs.get('best_mrr', 0.0):.4f}\")\n",
        "    \n",
        "    # Afficher les 5 derni√®res epochs\n",
        "    print(f\"\\nüìä 5 Derni√®res Epochs:\")\n",
        "    last_epochs = logs[\"epochs\"][-5:]\n",
        "    for epoch in last_epochs:\n",
        "        print(f\"\\n  Epoch {epoch['epoch']}:\")\n",
        "        print(f\"    Train Loss: {epoch['train_loss']:.4f}\")\n",
        "        if epoch.get('val_loss', 0) > 0:\n",
        "            print(f\"    Val Loss: {epoch['val_loss']:.4f}\")\n",
        "        print(f\"    LR: {epoch['learning_rate']:.6f}\")\n",
        "        if epoch.get('val_mrr', 0) > 0:\n",
        "            print(f\"    MRR: {epoch['val_mrr']:.4f}\")\n",
        "            print(f\"    R@1: {epoch['val_r1']:.4f}\")\n",
        "            print(f\"    R@5: {epoch['val_r5']:.4f}\")\n",
        "            print(f\"    R@10: {epoch['val_r10']:.4f}\")\n",
        "else:\n",
        "    print(\"Aucun mod√®le disponible.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
