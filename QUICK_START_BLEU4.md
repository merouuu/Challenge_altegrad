# QUICK START: BLEU-4 RETRIEVAL EVALUATION

## ‚ú® What's New?

Your training script now logs **BLEU-4 retrieval scores** during validation, enabling you to verify that hard negative mining actually improves text retrieval quality (the actual Kaggle metric).

---

## üîÑ Before vs After

### BEFORE: MRR-Only Optimization
```
Epoch 05 | Train Loss: 0.2134 | Val: Loss: 0.1567, MRR: 0.4012, R@1: 0.2891
         ‚Üë Only embedding-space metric, doesn't tell if text retrieval is good
```

### AFTER: MRR + BLEU-4
```
Epoch 05 | Train Loss: 0.2134 | Val: Loss: 0.1567, MRR: 0.4012, R@1: 0.2891, BLEU-4: 0.1234
         ‚Üë Now includes text retrieval quality metric (actual Kaggle scoring)
```

---

## üöÄ How to Use

### Option 1: Enable BLEU-4 in Command Line
```bash
python train_gt_contrast.py \
  --eval_bleu_bert \
  --epochs 100 \
  --batch_size 64
```

### Option 2: In Colab Notebook
Copy the code from `COLAB_TRAINING_WITH_BLEU4.ipynb` and run in Google Colab.

---

## üìä What to Expect

### Training Progress
```
Epoch 01 | Train Loss: 0.4521 | Val: MRR: 0.2345, BLEU-4: 0.0821    (random baseline)
Epoch 05 | Train Loss: 0.2134 | Val: MRR: 0.4012, BLEU-4: 0.1234    (random sampling)
Epoch 06 | Train Loss: 0.1876 | Val: MRR: 0.4234, BLEU-4: 0.1456    (hard negatives kick in)
Epoch 20 | Train Loss: 0.0654 | Val: MRR: 0.5234, BLEU-4: 0.2145    (improvement phase)
Epoch 50 | Train Loss: 0.0321 | Val: MRR: 0.5678, BLEU-4: 0.2456    (convergence)
```

### Key Signs
‚úÖ **Good:** BLEU-4 increases after curriculum switch (epoch 6+)  
‚úÖ **Good:** BLEU-4 and MRR move in the same direction  
‚ö†Ô∏è **Watch:** BLEU-4 stays at 0.08 - might need more training  
‚ö†Ô∏è **Watch:** BLEU-4 diverges from MRR - check text descriptions  

---

## üìà Monitor Results

### In JSON Logs
```python
import json

with open('output/training_logs.json', 'r') as f:
    logs = json.load(f)
    
# Extract BLEU-4 per epoch
for ep in logs['epochs']:
    print(f"Epoch {ep['epoch']:3d}: MRR={ep['val_mrr']:.3f}, BLEU-4={ep.get('val_bleu4', 0):.3f}")
```

### Visualization
The `COLAB_TRAINING_WITH_BLEU4.ipynb` notebook automatically creates:
- Training loss curve
- MRR/Recall@K curves
- **BLEU-4 curve** ‚Üê New!
- Learning rate schedule

---

## üéØ Performance Targets

| Metric | Epoch 1-5 | Epoch 6-20 | Epoch 30+ |
|--------|-----------|-----------|----------|
| **MRR** | 0.25-0.40 | 0.40-0.50 | 0.50-0.60 |
| **BLEU-4** | 0.08-0.12 | 0.12-0.18 | 0.20-0.28 |
| **Status** | Random | Curriculum | Converged |

If your values are significantly lower, check:
1. Are you using `--eval_bleu_bert` flag?
2. Is hard negative mining enabled?
3. Are text descriptions loaded correctly?

---

## ‚öôÔ∏è Configuration Recommendations

### Quick Start (laptop/local)
```bash
python train_gt_contrast.py \
  --eval_bleu_bert \
  --batch_size 32 \
  --epochs 30
```

### Colab Optimized (high performance)
```bash
python train_gt_contrast.py \
  --eval_bleu_bert \
  --hard_negatives \
  --curriculum_epoch 5 \
  --batch_size 128 \
  --epochs 100 \
  --use_augmentation \
  --temp_schedule
```

### Production (Kaggle submission)
```bash
python train_gt_contrast.py \
  --eval_bleu_bert \
  --hard_negatives \
  --curriculum_epoch 10 \
  --hard_ratio 0.6 \
  --hardness_k 100 \
  --batch_size 64 \
  --lr 0.0003 \
  --epochs 150
```

---

## üîß Files Changed

| File | Changes | Impact |
|------|---------|--------|
| `train_gt_contrast.py` | Added 4 functions + 3 integration points | ‚úÖ Core implementation |
| `BLEU4_INTEGRATION_SUMMARY.md` | Created | üìñ Technical details |
| `BLEU4_COMPLETE_GUIDE.md` | Created | üìñ Full documentation |
| `test_bleu4_functions.py` | Created | ‚úÖ Unit tests |
| `COLAB_TRAINING_WITH_BLEU4.ipynb` | Created | üöÄ Ready-to-run Colab |

---

## üí° Tips

### 1. BLEU-4 is Lower than Expected?
- This is normal! BLEU-4 is a strict metric (lexical matching)
- Expected range: 0.08-0.30 for retrieval task
- Compare against baseline: Random retrieval ‚Üí ~0.08

### 2. BLEU-4 and MRR Diverge?
- Check: Are text descriptions complete and clean?
- Solution: Increase hard_ratio (0.5 ‚Üí 0.7) to force more similarity
- Alternative: Add BERTScore evaluation (more flexible metric)

### 3. Want to Debug One Batch?
- Run: `python test_bleu4_functions.py`
- Validates tokenization and BLEU computation
- Confirms functions work correctly before full training

### 4. Running Out of Memory?
- Reduce batch_size (64 ‚Üí 32)
- BLEU evaluation doesn't use much memory, so it's likely the model itself
- Check: Is augmentation enabled? (Can use extra memory)

---

## ‚úÖ Verification

Run this to verify everything is working:
```bash
python test_bleu4_functions.py
```

Should see:
```
‚úÖ All BLEU-4 tests passed!
‚úÖ ALL TESTS PASSED!

Ready to integrate with train_gt_contrast.py
```

---

## üìû Troubleshooting

### BLEU-4 shows 0.0 constantly
```python
# Check 1: Is flag enabled?
# In command line, include: --eval_bleu_bert

# Check 2: Are texts loaded?
# Look for message: "Loaded X descriptions" in console
# If missing, descriptions aren't being loaded

# Check 3: Run test
python test_bleu4_functions.py
```

### BLEU-4 is NaN
- Usually means empty text in dataset
- Check: Do your graphs have descriptions in the right format?
- See: `load_id2text()` function in train_gt_contrast.py

### Memory error during BLEU evaluation
- Reduce batch_size for inference
- In code: `eval_bleu_retrieval(..., batch_size=32)`

---

## üéì Next Steps

1. ‚úÖ Read this file (you are here)
2. ‚è≠Ô∏è Run: `python train_gt_contrast.py --eval_bleu_bert --epochs 10` (quick test)
3. ‚è≠Ô∏è Check output: Look for "BLEU-4" in console output
4. ‚è≠Ô∏è Monitor: Watch BLEU-4 increase over epochs
5. ‚è≠Ô∏è Optimize: Tune hard_ratio, curriculum_epoch based on BLEU trajectory
6. ‚è≠Ô∏è Deploy: Use best checkpoint for Kaggle submission

---

## üìä Expected Output Format

### Console (per epoch)
```
Epoch 01/100 | Train Loss: 0.4521 | Val: Loss: 0.1234, MRR: 0.2345, R@1: 0.1456, BLEU-4: 0.0821
Epoch 05/100 | Train Loss: 0.2134 | Val: Loss: 0.1567, MRR: 0.4012, R@1: 0.2891, BLEU-4: 0.1234
Epoch 10/100 | Train Loss: 0.1456 | Val: Loss: 0.1012, MRR: 0.4567, R@1: 0.3234, BLEU-4: 0.1567
```

### JSON Logs (output/training_logs.json)
```json
{
  "epochs": [
    {
      "epoch": 1,
      "train_loss": 0.4521,
      "val_loss": 0.1234,
      "val_mrr": 0.2345,
      "val_bleu4": 0.0821
    },
    {
      "epoch": 5,
      "train_loss": 0.2134,
      "val_loss": 0.1567,
      "val_mrr": 0.4012,
      "val_bleu4": 0.1234
    }
  ]
}
```

---

**Status:** ‚úÖ Ready to use  
**Last Updated:** 2024-12-20  
**Time to First BLEU-4:** 2 minutes (run training with --eval_bleu_bert flag)
